{{- if and .Values.fileStorage.enabled .Values.fileStorage.nfs.enabled }}
apiVersion: v1
kind: PersistentVolume
metadata:
  name: {{ include "kraken.fullname" . }}-uploads-nfs
  labels:
    {{- include "kraken.labels" . | nindent 4 }}
spec:
  capacity:
    storage: {{ .Values.fileStorage.size }}
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  {{- if and (hasKey .Values.fileStorage "mountOptions") (gt (len .Values.fileStorage.mountOptions) 0) }}
  # Custom NFS mount options from values.yaml
  mountOptions:
    {{- toYaml .Values.fileStorage.mountOptions | nindent 4 }}
  {{- else }}
  # Default resilient NFS mount options to prevent stale file handles
  # Using NFSv3 with TCP (more stable than v4.1 for this export configuration)
  mountOptions:
    - nfsvers=3          # Use NFSv3 (stable, well-supported)
    - hard               # Retry indefinitely on server failure (never give up)
    - intr               # Allow signals to interrupt hung NFS operations
    - timeo=600          # Initial timeout: 60 seconds (600 deciseconds)
    - retrans=2          # Retry 2 times before reporting timeout
    - rsize=1048576      # 1MB read buffer (better performance)
    - wsize=1048576      # 1MB write buffer (better performance)
    - tcp                # Use TCP transport (more reliable than UDP) - KEY FIX
    - noatime            # Don't update access time (reduces server load)
    - nodiratime         # Don't update directory access time
    - _netdev            # Wait for network before mounting
    - actimeo=30         # Attribute cache timeout: 30 seconds (reduces server calls)
  {{- end }}
  nfs:
    server: {{ .Values.fileStorage.nfs.server }}
    path: {{ .Values.fileStorage.nfs.path }}
{{- end }}
---
{{- if and .Values.replayStorage.enabled .Values.replayStorage.nfs.enabled }}
apiVersion: v1
kind: PersistentVolume
metadata:
  name: {{ include "kraken.fullname" . }}-replay-segments-nfs
  labels:
    {{- include "kraken.labels" . | nindent 4 }}
spec:
  capacity:
    storage: {{ .Values.replayStorage.size }}
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  # Optimized NFS mount options for LiveKit egress segments
  # Critical: Do NOT use nolock or actimeo as they cause stale file handle issues
  mountOptions:
    - hard               # Retry indefinitely on server failure (never give up)
    - nfsvers=3          # Use NFSv3 (stable, well-supported)
    - intr               # Allow signals to interrupt hung NFS operations
    - timeo=600          # Initial timeout: 60 seconds (600 deciseconds)
    - retrans=2          # Retry 2 times before reporting timeout
    - rsize=1048576      # 1MB read buffer (better performance)
    - wsize=1048576      # 1MB write buffer (better performance)
    - tcp                # Use TCP transport (more reliable than UDP)
    - noatime            # Don't update access time (reduces server load)
    - nodiratime         # Don't update directory access time
  nfs:
    server: {{ .Values.replayStorage.nfs.server }}
    path: {{ .Values.replayStorage.nfs.path }}
{{- end }}
